{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duvvusuribabu/student-dropout-prediction-/blob/main/ADS_HACKATHON_16_8_2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ADVANCE DATA SCIENCE HACKATHON - (16/08/22 - 17/08/22)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "TEAM : CODE BUDDIES\n",
        "\n",
        " ##  Prediction of Student Dropouts\n"
      ],
      "metadata": {
        "id": "QCSh-dndXaQX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> *Importing the required libraries*"
      ],
      "metadata": {
        "id": "V68VvLsqYcJp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7p_FHPH2P1Gp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> *Loading the dataset*"
      ],
      "metadata": {
        "id": "seSr8C1NY0cD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/student-data.csv')\n",
        "data.head(3)"
      ],
      "metadata": {
        "id": "XRyVIOlzQvfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "q84ReGigY4gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "VgIv4I8el1Ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above, it is clear that the dataset contains `31` features with `395` records."
      ],
      "metadata": {
        "id": "DV772l06l4W4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Total number of students : {}'.format(data.shape[0]))\n",
        "\n",
        "print('Total number of students  passed: {}'.format(len(data[data.passed=='yes'])))\n",
        "\n",
        "print('Total number of students  failed: {}'.format(len(data[data.passed=='no'])))\n",
        "\n",
        "print('Pass percentage: {}%'.format(round(len(data[data.passed=='yes'])/data.shape[0],2)*100))"
      ],
      "metadata": {
        "id": "BMeA2vx_lbJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "XMeiClvJSD1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*From the above output we concluded that there are no null values but there are some features that has non int values. These values have to converted to numerical categorical data.*"
      ],
      "metadata": {
        "id": "3GA02fL7jKSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> *Convertion of values of Object type to Integer type:*\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j7VOOTv5hkxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in data.columns:\n",
        "  print(i,set(data[i].values))"
      ],
      "metadata": {
        "id": "Ds3ZOf5gklRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code helps us to have a glance at the unique values present in each feature of the dataset."
      ],
      "metadata": {
        "id": "9WD8ZlJMray6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# objCols = ['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'passed']\n",
        "# data[objCols] = data[objCols].apply(le.fit_transform)\n",
        "\n",
        "# objCols=[]\n",
        "# for name in feature_names:\n",
        "#   if data[name].dtype =='object':\n",
        "#     objCols.append(name)\n",
        "# data[objCols] = data[objCols].apply(le.fit_transform)\n",
        "\n",
        "\n",
        "feature_names = data.columns.values\n",
        "\n",
        "for name in feature_names:\n",
        "  if data[name].dtype =='object':\n",
        "    data[name] = le.fit_transform(data[name])\n",
        "data.head()\n"
      ],
      "metadata": {
        "id": "1lU2EENUQ45y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Now we find that the data set is transformed into a dataset with only integer values.*"
      ],
      "metadata": {
        "id": "KWvBcUjYqI7H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*As we know that the model can't be trained on the categorical data, so we converted the values of object type into integer type.*"
      ],
      "metadata": {
        "id": "SaGfFD37GGtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sns.catplot(x=\"passed\", kind=\"count\", data=data)\n",
        "sns.countplot('passed', data=data)\n",
        "plt.title('Passed?')"
      ],
      "metadata": {
        "id": "G5iCyStinIxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Passed_data =[data.passed.value_counts()]\n",
        "\n",
        "print(\"Total passed(1): {}\".format(Passed_data[0][1]))\n",
        "print(\"Pass Percentage: {}\\n\".format(round(Passed_data[0][1]*100/(Passed_data[0][0]+Passed_data[0][1]),2)))\n",
        "\n",
        "print(\"Total Dropped Out(0): {}\".format(Passed_data[0][0]))\n",
        "print(\"Dropout Percentage Percentage: {}\".format(round(Passed_data[0][0]*100/(Passed_data[0][0]+Passed_data[0][1]),2)))"
      ],
      "metadata": {
        "id": "9sjclMItrB1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*For optimal/high accuracy, a good dataset must not contain features with high correaltion among them.\n",
        "The `.corr()` method of pandas library helps us to find the co-relation among the features.*"
      ],
      "metadata": {
        "id": "tbdMTHhmqUvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corMatrix = data.corr().abs()\n",
        "corMatrix"
      ],
      "metadata": {
        "id": "P0HVS5tdQc7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Since the upper triangle and lower triangle matrices are same, we shall consider any one of them.*"
      ],
      "metadata": {
        "id": "s93dcIqYq0Ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    upper_matrix = corMatrix.where(np.triu(np.ones(corMatrix.shape),k=1).astype(np.bool_))\n",
        "    upper_matrix.head()"
      ],
      "metadata": {
        "id": "j7FCgjukRCye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_columns = [col for col in upper_matrix if any(upper_matrix[col]>0.65)]\n",
        "print(drop_columns)"
      ],
      "metadata": {
        "id": "wtEJ1fkERvtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The features of the dataset are not highly co-related. Hence, no features are required to be removed.*"
      ],
      "metadata": {
        "id": "ixIJ3QTajVGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('passed',axis=1)\n",
        "y= data.passed"
      ],
      "metadata": {
        "id": "6BaxIzQlZEea"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffled_df = data.sample(frac=1,random_state=4)\n",
        "\n",
        "# dropped_df = shuffled_df.loc[shuffled_df['passed'] == 0]\n",
        "# passed_df = shuffled_df.loc[shuffled_df['passed'] == 1].sample(n=130,random_state=42)\n",
        "\n",
        "# normalized_df = pd.concat([dropped_df, passed_df])\n",
        "\n",
        "# plt.figure(figsize=(8, 8))\n",
        "# sns.countplot('passed', data=normalized_df)a\n",
        "# plt.title('Balanced Classes')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "Tndsuo_t8kW5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
        "\n",
        "sel = SelectFromModel(DecisionTreeClassifier())\n",
        "sel.fit(X_train, y_train)\n",
        "\n",
        "sel.get_support()\n",
        "selected_feat= X_train.columns[(sel.get_support())]\n",
        "selected_feat"
      ],
      "metadata": {
        "id": "lrXzskcHSML8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data=data, columns=selected_feat)\n",
        "df_target = data['passed']\n",
        "# df1 = pd.concat([df, df_target], ignore_index=True, sort=False)\n",
        "df = df.join(df_target, lsuffix='_caller', rsuffix='_other')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "dM2JZdADSLc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('passed',axis=1)\n",
        "y = df.passed"
      ],
      "metadata": {
        "id": "6mvSrshPTbcd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "\n",
        "# rus = RandomUnderSampler() \n",
        "# X, y = rus.fit_resample(X, y)\n",
        "\n",
        "\n",
        "ros = RandomOverSampler()\n",
        "X, y = ros.fit_resample(X, y)\n",
        "\n",
        "\n",
        "# sampler = SMOTE()\n",
        "# X, y = sampler.fit_resample(X, y)\n",
        "\n",
        "# # data.isnull().sum()\n",
        "\n",
        "# X = X_ros\n",
        "# y = y_ros"
      ],
      "metadata": {
        "id": "GZVbC7nQ-osu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()"
      ],
      "metadata": {
        "id": "HDbj7PEy9XZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Visualization"
      ],
      "metadata": {
        "id": "MvpFZbQ1GqJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*By using pandas, matplotlib and seaborn libraries we can visualize the data graphically and can understand more clearly.*"
      ],
      "metadata": {
        "id": "gGG2zN5iG3lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist(edgecolor='black',bins = 25, figsize= (20,20))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7KknnKKVHbrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The `hist()` method of pandas is used to represent the histograms of each feature specified in the data frame.*"
      ],
      "metadata": {
        "id": "_LbKQprcJJzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30,30))\n",
        "sns.heatmap(df.corr(), cmap=\"YlGnBu\", annot=True)"
      ],
      "metadata": {
        "id": "wG9SZh5gJuje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Splitting data for Training and Testing"
      ],
      "metadata": {
        "id": "ascif-5Cn7GE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)"
      ],
      "metadata": {
        "id": "zoQQ-pn6luZh"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Training the models and Evaluating their performance"
      ],
      "metadata": {
        "id": "cP_74kM1o2mL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Since the target feature is categorical, the Machine learning models that are used to train and predict on this dataset should be of type Classification.*"
      ],
      "metadata": {
        "id": "lED_rroott5i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The various metrics for evaluating Classification models are*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> Confusion matrix\n",
        " *   Accuracy\n",
        " *   Recall\n",
        " *   Precision\n",
        " *   F1_score\n",
        " \n",
        "> Classification Report\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XswSI2xLuHHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score"
      ],
      "metadata": {
        "id": "tch_YUI4uFop"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_df=pd.DataFrame({'Model':[], 'F1_score':[], 'Accuracy':[]})"
      ],
      "metadata": {
        "id": "h_azwXrEwjUU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "-j3WwoiowG0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*`Logistic Regression` is used for predicting the categorical dependent variable using a given set of independent variables.*"
      ],
      "metadata": {
        "id": "vVaqD4XKvilw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "model = LogisticRegression(C=0.1, max_iter=250)\n",
        "\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "# print('{}\\'s Accuracy :{}'.format(type(model).__name__,accuracy_score(y_test, y_pred)))\n",
        "print('{}\\'s F1_Score :{}'.format(type(model).__name__,f1_score(y_test, y_pred)))\n",
        "\n",
        "scores_df = scores_df.append(pd.DataFrame({'Model':[type(model).__name__],\n",
        "                               'F1_score':[f1_score(y_test, y_pred)],\n",
        "                               'Accuracy':[accuracy_score(y_test, y_pred)]\n",
        "                               }), ignore_index=True)"
      ],
      "metadata": {
        "id": "5mRAbtMdjrPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Accuracy of LogisticRegression is 0.72 and F1_score is 0.82"
      ],
      "metadata": {
        "id": "79QJ3iiUFkQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes ( BernoulliNB )"
      ],
      "metadata": {
        "id": "tDQnYmB98YIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*`NaÃ¯ve Bayes` algorithm is a supervised learning algorithm, which is based on Bayes theorem and used for solving classification problems.\n",
        "It is a probabilistic classifier, which means it predicts on the basis of the probability of an object.*"
      ],
      "metadata": {
        "id": "cI7wC7-48hwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#naive bayes\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "model = BernoulliNB()\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "# print('{}\\'s Accuracy :{}'.format(type(model).__name__,accuracy_score(y_test, y_pred)))\n",
        "print('{}\\'s F1_Score :{}'.format(type(model).__name__,f1_score(y_test, y_pred)))\n",
        "\n",
        "scores_df = scores_df.append(pd.DataFrame({'Model':[type(model).__name__],\n",
        "                               'F1_score':[f1_score(y_test, y_pred)],\n",
        "                               'Accuracy':[accuracy_score(y_test, y_pred)]\n",
        "                               }), ignore_index=True)"
      ],
      "metadata": {
        "id": "OyNry55rohui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Accuracy of Bernoulli Naive Bayes Classifier is 0.75 and F1_score is 0.84"
      ],
      "metadata": {
        "id": "UpTTO4FRFLqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K Nearest Neighbour\n",
        "\n",
        "*`K-NN` algorithm assumes the similarity between the new case/data and available cases and put the new case into the category that is most similar to the available categories.*"
      ],
      "metadata": {
        "id": "cxozzjBWMi4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors=7, algorithm='auto')\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "confusion_matrix(y_test, y_pred)\n",
        "# print('{}\\'s Accuracy :{}'.format(type(model).__name__,accuracy_score(y_test, y_pred)))\n",
        "print('{}\\'s F1_Score :{}'.format(type(model).__name__,f1_score(y_test, y_pred)))\n",
        "\n",
        "scores_df = scores_df.append(pd.DataFrame({'Model':[type(model).__name__],\n",
        "                               'F1_score':[f1_score(y_test, y_pred)],\n",
        "                               'Accuracy':[accuracy_score(y_test, y_pred)]\n",
        "                               }), ignore_index=True)"
      ],
      "metadata": {
        "id": "FyyuWKrMpk4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Accuracy of KNN Classifier is 0.68 and F1_score is 0.81"
      ],
      "metadata": {
        "id": "34iTWzE7FGvI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree\n",
        "\n",
        "*`Decision Tree` is a tree-structured classifier, where internal nodes represent the features of a dataset, branches represent the decision rules and each leaf node represents the outcome.*"
      ],
      "metadata": {
        "id": "2DV1JdMFNusQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#decision tree\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model = DecisionTreeClassifier(criterion='gini')\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "# print('{}\\'s Accuracy :{}'.format(type(model).__name__,accuracy_score(y_test, y_pred)))\n",
        "print('{}\\'s F1_Score :{}'.format(type(model).__name__,f1_score(y_test, y_pred)))\n",
        "\n",
        "scores_df = scores_df.append(pd.DataFrame({'Model':[type(model).__name__],\n",
        "                               'F1_score':[f1_score(y_test, y_pred)],\n",
        "                               'Accuracy':[accuracy_score(y_test, y_pred)]\n",
        "                               }), ignore_index=True)"
      ],
      "metadata": {
        "id": "XmKtvoALr5g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Accuracy of Decision Tree Classifier is 0.68 and F1_score is 0.77"
      ],
      "metadata": {
        "id": "kfvp8s8vE9kf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine\n",
        "\n",
        "*`SVM` algorithm creates the best line or decision boundary that can segregate n-dimensional space into classes so that we can easily put the new data point in the correct category in the future. This best decision boundary is called a hyperplane.*"
      ],
      "metadata": {
        "id": "7L60C0VbN94P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# svm\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC(C=0.1)\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "confusion_matrix(y_test, y_pred)\n",
        "# print('{}\\'s Accuracy :{}'.format(type(model).__name__,accuracy_score(y_test, y_pred)))\n",
        "print('{}\\'s F1_Score :{}'.format(type(model).__name__,f1_score(y_test, y_pred)))\n",
        "\n",
        "scores_df = scores_df.append(pd.DataFrame({'Model':[type(model).__name__],\n",
        "                               'F1_score':[f1_score(y_test, y_pred)],\n",
        "                               'Accuracy':[accuracy_score(y_test, y_pred)]\n",
        "                               }), ignore_index=True)"
      ],
      "metadata": {
        "id": "qL743Qr-uIGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Accuracy of Support Vector Machine Classifier is 0.71 and F1_score is 0.83"
      ],
      "metadata": {
        "id": "L43y02HkE1Un"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest Classifier\n",
        "\n",
        "*`Random Forest` is a classifier that contains a number of decision trees on various subsets of the given dataset and takes the average to improve the predictive accuracy of that dataset.*"
      ],
      "metadata": {
        "id": "NBB6rEAiNzCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#random forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators=13, criterion='gini',max_depth=10, max_features='auto')\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "confusion_matrix(y_test, y_pred)\n",
        "# print('{}\\'s Accuracy :{}'.format(type(model).__name__,accuracy_score(y_test, y_pred)))\n",
        "print('{}\\'s F1_Score :{}'.format(type(model).__name__,f1_score(y_test, y_pred)))\n",
        "\n",
        "scores_df = scores_df.append(pd.DataFrame({'Model':[type(model).__name__],\n",
        "                               'F1_score':[f1_score(y_test, y_pred)],\n",
        "                               'Accuracy':[accuracy_score(y_test, y_pred)]\n",
        "                               }), ignore_index=True)"
      ],
      "metadata": {
        "id": "jwLTiZuB0IUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Accuracy of Random Forest Classifier is 0.75 and F1_score is 0.83"
      ],
      "metadata": {
        "id": "VJefQU5uEvZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Here we are using `Yellowbrick` for visualization of model prediction*"
      ],
      "metadata": {
        "id": "fIW4hBtvEq34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [1,0]\n",
        "from yellowbrick.classifier import ConfusionMatrix\n",
        "visualizer = ConfusionMatrix(model, classes=classes, support=True) \n",
        "visualizer.fit(X_train, y_train) \n",
        "visualizer.score(X_test, y_test)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pJsbw_DZIwlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from yellowbrick.classifier import ClassificationReport\n",
        "visualizer = ClassificationReport(model, classes=classes, support=True) \n",
        "visualizer.fit(X_train, y_train) \n",
        "visualizer.score(X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pt1E7GTCgpgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(y_test,y_pred)\n",
        "plt.xlabel(\"Predicted Y\")\n",
        "plt.ylabel(\"Actual Y\")\n",
        "plt.title(\"Predicted against Actual plot\")"
      ],
      "metadata": {
        "id": "mJTrzEPdu_wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBOOST"
      ],
      "metadata": {
        "id": "73bdWrj7N5l2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost"
      ],
      "metadata": {
        "id": "4V_VxNa41o0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d201e26-68b3-4d2c-eb8a-fdd6bf0f0aae"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "numeric_pipeline = Pipeline(\n",
        "    steps=[(\"impute\", SimpleImputer(strategy=\"mean\")), \n",
        "           (\"scale\", StandardScaler())]\n",
        ")\n",
        "num_cols = X.select_dtypes(include=\"number\").columns\n",
        "\n",
        "full_processor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"numeric\", numeric_pipeline, num_cols),\n",
        "    ]\n",
        ")\n",
        "\n",
        "X_processed = full_processor.fit_transform(X)\n",
        "y_processed = SimpleImputer(strategy=\"most_frequent\").fit_transform(\n",
        "    y.values.reshape(-1, 1)\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_processed, y_processed, stratify=y_processed, random_state=50\n",
        ")\n",
        "\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "# print('{}\\'s Accuracy :{}'.format(type(model).__name__,round(accuracy_score(y_test, y_pred),2)))\n",
        "print('{}\\'s F1_Score :{}'.format(type(model).__name__,f1_score(y_test, y_pred)))\n",
        "\n",
        "scores_df = scores_df.append(pd.DataFrame({'Model':[type(model).__name__],\n",
        "                               'F1_score':[f1_score(y_test, y_pred)],\n",
        "                               'Accuracy':[accuracy_score(y_test, y_pred)]\n",
        "                               }), ignore_index=True)"
      ],
      "metadata": {
        "id": "QazmoykI9iXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Accuracy of XGBOOST Classifier is 0.72 and F1_score is 0.81"
      ],
      "metadata": {
        "id": "6Wj2vgwVEc7o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the data is unbalanced F1_score is considered superior to model accuracy in determining the better ML algorithm."
      ],
      "metadata": {
        "id": "205GK3EPdB4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, the Accuracy and F1_Score of different models stated above are"
      ],
      "metadata": {
        "id": "9dU5aH-r6xZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores_df"
      ],
      "metadata": {
        "id": "x5qAYXD36w1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Artificail Neural Networks**"
      ],
      "metadata": {
        "id": "xySx-QCrey5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*On the other hand we can also use the ann(artificial neural networks) models to perform the classification as well as Regression problems.*"
      ],
      "metadata": {
        "id": "CTz-KWHmfDmQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">Importing the required libraries"
      ],
      "metadata": {
        "id": "w4c51eQJfbKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "riAsGnGTKRaW"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(12, activation=\"relu\"))\n",
        "model.add(Dense(8, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "5Q0-zkodKV98"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "jNmfN-DqLCPM"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=20, batch_size=5)"
      ],
      "metadata": {
        "id": "GbBBlKpFLah0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "kt51EvXjNO4L",
        "outputId": "d27f5b6b-dc44-42c6-c082-12b3bbed7345",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Among the above classifiers `Random Forest Classifier` performs well on this dataset. It has higher values in terms of both Accuracy - 80% and F1 Score - 0.85(approximately)\n",
        "\n",
        "The deployment of this model can be seen here - [LINK](https://dropout-predictor.herokuapp.com)"
      ],
      "metadata": {
        "id": "iX6-iWeafzwi"
      }
    }
  ]
}